---
title: "Confidence intervals - minilab"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

<div class="blame">
author: "Del Middlemiss"<br>
date: "30th August 2019"
</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

**Duration - 45 minutes**<br>

<hr>

# Introduction 

In this lab we're going to draw multiple samples from a population, calculate a bootstrapped $95\%$ CI for each, and then see how often the population parameter lies within the CI. Hopefully this will help you to understand what we mean by 'confidence':

<br>
<center>
*'If we draw 1000 repeated samples from a population, and form a $95\%$ CI for each for a parameter estimate, then, on average, we are _confident_ that approximately $950$ CIs _will_ contain the true population parameter, and approximately $50$ _will not_. This is what we will try to show below.'*
</center>
<br>

<br>
<div class='emphasis'>
As in the earlier lab on sampling, do remember that this is something of a 'fake' situation, and we are doing this just for educational purposes. Normally, we would have a single sample drawn from a population, and a single CI created from that sample at whatever confidence level we like. We would not be able to repeatedly sample the population in the way that we will below.
</div>
<br>

<hr>

# MVP

<br>

* We are going to use a dataset on house sales in Ames, Iowa over a number of years. We will be interested in the `SalePrice` of houses (though we should `clean_names()` the data, so this will end up as `sale_price`). Load the data and explore it.

```{r, message=FALSE}
library(tidyverse)
library(infer)
library(janitor)
```

```{r, message=FALSE}
ames <- read_csv("data/ames.csv")
ames <- clean_names(ames)
glimpse(ames)
```

<br>

* Plot a histogram of `sale_price`. Is the distribution normal?

```{r}
ames %>%
  ggplot(aes(x = sale_price)) +
  geom_histogram(col = "white")
```
It is not normal, we see significant right-skew.

<br>

* Calculate the population parameter mean of `sale_price`. Store it in a variable, as we'll need this value later when we check if each CI contains the parameter value or not.

```{r}
param <- ames %>%
  summarise(mean_sale_price = mean(sale_price))
param
```

<br>

* Now we are going to:
  - take $1000$ random samples each of size $100$ from `sale_price` in `ames`
  - create a boostrap sampling distribution of `mean(sale_price)` from each $100$-observation sample (use 1000 reps)
  - calculate the $95\%$ CI for each bootstrap distribution 
  - store the upper and lower bounds of the CI in a tibble called `results` 
  
Use the `infer` workflow to generate the bootstrap distributions and CIs. This code will be pretty hard to write. Think about wrapping the sample creation and `infer` code in a `for` loop to generate $1000$ random samples and CIs. Create an empty `results` tibble before the loop, and `bind_rows()` to it every time you generate a new set of CI bounds.  

There's an outline of the code below, and the full solution below that (if you get stuck). Have a go, but don't spend too long on this, it's more important to spend your time thinking about CIs!  

<details>
<summary>**Code outline**</summary>
```{r, eval=FALSE}
results <- tibble()
for (sample_num in 1:1000){

  # get a new 100-observation random sample from ames
  this_sample <- ames %>%

  # create a bootstrap distribution of mean(sale_price)
  # use 1000 reps
  this_bootstrap <- this_sample %>%

  # get 95% CI for this_bootstrap distribution
  this_ci <- this_bootstrap %>%

  # prepare new row for results, storing this_ci bounds
  this_result <- c(
    sample_num = sample_num, 
    lower = this_ci[[1]], 
    upper = this_ci[[2]]
  )
  
  # add this_result to growing tibble of results
  results <- 
}
```
</details>

<details>
<summary>**Full solution**</summary>
```{r}
results <- tibble()
for (sample_num in 1:1000){

  # get a new 100-observation random sample from ames
  this_sample <- ames %>%
    rep_sample_n(size = 100, reps = 1) %>%
    ungroup() %>%
    select(sale_price)
  
  # create a bootstrap distribution of mean(sale_price)
  # use 1000 reps
    this_bootstrap <- this_sample %>%
    specify(response = sale_price) %>%
    generate(reps = 1000, type = "bootstrap") %>%
    calculate(stat = "mean")

  # get 95% CI for this bootstrap distribution
  this_ci <- this_bootstrap %>%
    get_ci(level = 0.95, type = "percentile")
  
  # prepare new row for results, storing CI bounds
  this_result <- c(
    sample_num = sample_num, 
    lower = this_ci[[1]], 
    upper = this_ci[[2]]
  )
  
  # add this_result to growing tibble of results
  results <- bind_rows(results, this_result)
}
```
</details>

<br>

* Pipe `results` to `mutate()` to add a new variable `popn_param_in_ci` which will be `TRUE` if the population parameter we calculated earlier is between `lower` and `upper`, and `FALSE` otherwise.

```{r}
results <- results %>%
  mutate(popn_param_in_ci = lower <= param$mean_sale_price & param$mean_sale_price <= upper)
```

<br>

* Perform an appropriate `summarise()` to determine the proportion of CIs that contain the population parameter. Our confidence level was $95\%$. Is your proportion close to that value.

```{r}
results %>%
  summarise(proportion_CI_containing_popn_param = mean(popn_param_in_ci))
```

<br>

* Have a think about what all this means, make a list of any points you don't understand. 
  - Imagine you had only a single $100$-observation sample of the `ames` data (say from a $100$ house survey). 
  - Would you know ahead of time whether the CI for `mean(sale_price)` from **your particular sample** contains the correct population parameter or not?
