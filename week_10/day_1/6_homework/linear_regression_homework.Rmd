---
title: "Simple linear regression homework"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---

<div class="blame">
author: "Del Middlemiss"<br>
date: "4th June 2019 - rev. 24th July 2019"
</div>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

<hr>

# Residuals vs. leverage

Read [this material](https://boostedml.com/2019/03/linear-regression-plots-residuals-vs-leverage.html) on the **leverage** of points in regression, and how to interpret the `Residuals vs Leverage` diagnostic plot produced by plotting the `lm()` model object. So far we've been using the `autoplot()` function to plot the model objects produced by `lm()`, but you can see the base `R` equivalent by doing something like `plot(model)` where `model` is an `lm()` object.

<hr>

# `project_management` analysis

The file `project_management.csv` contains data sampled from the recent work schedule of a small construction company. Column `estimated_length` contains the estimated length of a building job in days, while column `actual_length` contains the actual recorded length of the job in days. 

We are interested in determining the accuracy of the job estimations made by the company using simple linear regression.

<br>

* Load the data into a dataframe `project`

<br>

* Plot the data, taking `estimated_length` as the independent variable and `actual_length` as the dependent variable. 

<br>

* Label the data points with their row number in the data frame using `geom_text()` [**Hint** - you can pass `aes(label = 1:nrow(project))` to this layer to generate row index labels]
  - Identify by eye any points you think might be outliers and note their labels.
  - Further split your outliers into those you think are 'influential' or 'non-influential' based on a visual assessment of their leverage.

<br>

* Regress `actual_length` on `estimated_length` and confirm your visual assessment of which points are 'influential' or 'non-influential' outliers based on Cook's distance. You can get a useful plot of Cook's distance by passing argument `which = 4` to `autoplot()`. Or try the base `R` `plot()` function for comparison [e.g. `plot(model)]`! 

<br>

* Obtain the intercept and regression coefficient of variable `estimated_length` for a simple linear model fitted to data **omitting one of your non-influential outlier points**. 
  - How different are the intercept and coefficient from those obtained above by fitting the full data set? Does this support classifying the omitted point as non-influential? 
  - Plot the data points, this regression line and the regression line for the full data set. How different are the lines?

<br>

* Repeat the procedure above, but this time **omitting one of your influential outliers**. 


<br>

* Return to your fitted model for the complete data set and examine and comment upon the `Residuals vs Fitted`, `Normal Q-Q` and `Scale-Location` diagnostic plots. Are the regression assumptions reasonably satisfied?

<hr>

# Additional resources

* There are various techniques to perform what is known as 'robust regression' on a dataset. Robust methods are less affected by the presence of outliers. See the `rlm()` function ('robust linear model') in the `MASS` package and [this](http://www.alastairsanderson.com/R/tutorials/robust-regression-in-R/) blog post.



